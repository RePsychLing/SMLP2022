---
title: "Nahsime Bahmanian: Number Agreement"
subtitle: "RePsychLing SMLP2022"
author: "Reinhold Kliegl"
date: "2022-09-03 (last revised: `r format(Sys.time())`)"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options: 
  chunk_output_type: console
jupyter: julia-1.8
---

# Modeling issues

In the majority of the models, we had to simplify due to convergence issues. But even in the simplified models, we are facing singularity issue. I know that we should not simply ignore singularity warnings, but we decided not to simplify our models further. So, in addition to how to resolve convergence issues without oversimplifying a model, I would like to discuss singularity during the summer school and better understand the consequences of ignoring it. 

# Background 

The topic is number agreement errors made by Spanish native speakers in a web-based pronoun production experiment (Experiment 1: number agreement, created in May 2022 by Sol Lago and Nasimeh Bahmanian. In this experiment participants were asked to describe scenes of moving objects by producing sentences (in Spanish) like the English example below:

```
   *The shield(s)* pipped  *the hat(s)*  below/above    *it/them*
    antecedent              attractor                    pronoun
```

The antecedent and the attractor either matched or mismatched in number. We are interested to see if responses in mismatch conditions differs from match conditions (1) in terms of accuracy, i.e. whether participants made agreement errors in producing the pronoun. (2) in term of latency in planning/production of the pronoun in error-free responses. For the latter, we are looking at the duration  of critical regions as well as the likelihood of a non-zero pause 
immediately before the critical region.

# Setup

## Environment

```{julia}
#| label: environment
#| echo: false
#| output: false
using Pkg; Pkg.activate(".")
```

## Packages

```{julia}
#| label: packages

using AlgebraOfGraphics
using Arrow
using CairoMakie       # graphics back-end
using CategoricalArrays
using Chain
using DataFrames
using DataFrameMacros  # simplified dplyr-like data wrangling 
using MixedModels
using MixedModelsMakie # diagnostic plots
using ProgressMeter
using Random           # random number generators
using RCall            # call R from Julia
using StatsModels

using AlgebraOfGraphics: boxplot
using AlgebraOfGraphics: density

using MixedModelsMakie: qqnorm
using MixedModelsMakie: ridgeplot
using MixedModelsMakie: scatter
using MixedModelsMakie: caterpillar

ProgressMeter.ijulia_behavior(:clear);
CairoMakie.activate!(; type="svg");
```

## Data 

### Accuracy

```{julia}
#| label: dat_acc

dat_acc = DataFrame(Arrow.Table("./data/Bahmanian_acc.arrow"));
# transfromations using DataFrameMacros
@transform!(dat_acc, :Strct = :Strct == "no_preposition" ? "without" : "with");
@transform dat_acc begin
          :Subj = @bycol categorical(:Subj)
          :Item = @bycol categorical(:Item)
          :Match= @bycol categorical(:Match)
          :ACN  = @bycol categorical(:ACN)      
          :Strct= @bycol categorical(:Strct)
end; 
@transform!(dat_acc, :Nerr = Int(:nerr));

describe(dat_acc)
```

### Duration

```{julia}
#| label: dat_dur
#| 
dat = DataFrame(Arrow.Table("./data/Bahmanian_dur.arrow"));
ok1 = collect(keys(skipmissing(dat.dur)));

# alternative: use Julius Krumbiegel's `Chain` package
ok2 = @chain dat.dur begin
  skipmissing
  keys
  collect
end;

# do we collect the same indices?
display(ok1 == ok2)

dat_dur = dat[ok1, : ]; # keeping rows with valid dur's'
@transform!(dat_dur, :Strct = :Strct == "no_preposition" ? "without" : "with");
@transform dat_dur begin
          :Subj = @bycol categorical(:Subj)
          :Item = @bycol categorical(:Item)
          :Match= @bycol categorical(:Match)
          :ACN  = @bycol categorical(:ACN)      
          :Strct= @bycol categorical(:Strct)
end;          
@transform!(dat_dur, :ldur = log(:dur));

describe(dat_dur)

gdur = groupby(dat_dur, :Segment);
```

# Contrasts

+ ACN:   effect coded (-1 singular,  +1 plural)
+ Match: effect coded (-1 match,     +1 mismatch)
+ Strct: effect coded (-1 without,   +1 with)

```{julia}
#| label: contrasts

contrasts = merge(
      Dict(:Match => EffectsCoding(base= "match"; levels=["match", "mismatch"])),
      Dict(:ACN   => EffectsCoding(base= "singular"; levels=["singular", "plural"])),
      Dict(:Strct => EffectsCoding(base= "without"; levels=["without", "with"])),
      Dict(:Subj  => Grouping()),
      Dict(:Item  => Grouping())
   );
```

# LMMs for duration 

### Segment: Adverb + pronoun region

This data are in `gdur[7]`

#### AntecedentNumber * Match

We start with a fairly low complex LMM. 

```{julia}
#| label: voi_dur

voi_dur = let
  form= @formula(ldur ~ 1 + ACN * Match +  (1 | Subj) + (1 | Item))
  fit(MixedModel, form, gdur[7]; contrasts)
end
```

Very small VC for `Item.`

```{julia}
#| label: smp1_dur

smp1_dur = let
  form= @formula(ldur ~ 1 + ACN * Match + 
                       (1 + ACN + Match | Subj) + zerocorr(0 + ACN&Match | Subj) +
               zerocorr(1 + ACN | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(smp1_dur))  # ok
display(smp1_dur.PCA[:Subj])   # ok
display(smp1_dur.PCA[:Item])   # ok

display(VarCorr(smp1_dur))

lrtest(voi_dur, smp1_dur)
```

```{julia}
#| label: smp2_dur

smp2_dur = let
  form= @formula(ldur ~ 1 + ACN * Match + 
                       (1 + ACN * Match | Subj) +
               zerocorr(1 + ACN | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(smp2_dur))  # ok
display(smp2_dur.PCA[:Subj])   # ok
display(smp2_dur.PCA[:Item])   # ok

display(VarCorr(smp2_dur))
```

```{julia}
#| label: smp3_dur

smp3_dur = let
  form= @formula(ldur ~ 1 + ACN * Match + 
                       (1 + ACN * Match | Subj) +
                       (1 + ACN | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(smp3_dur))  # not ok
display(smp3_dur.PCA[:Subj])   # not ok
display(smp3_dur.PCA[:Item])   # not ok

display(VarCorr(smp2_dur))

lrtest(smp1_dur, smp3_dur)
```

```{julia}
#| label: max_dur

max_dur = let
  form= @formula(ldur ~ 1 + ACN * Match + 
                       (1 + ACN * Match | Subj) + 
                       (1 + ACN * Match | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(max_dur))  # not ok
display(max_dur.PCA[:Subj])   # ok
display(max_dur.PCA[:Item])   # not ok

VarCorr(max_dur)

lrtest( smp3_dur, max_dur)
```

Overparameterized in `Item`.

#### AntecedentNumber / Match

```{julia}
#| label: smp2_dur_n

smp2_dur_n = let
  form= @formula(ldur ~ 1 + ACN / Match + 
                       (1 + ACN / Match | Subj) +
               zerocorr(1 + ACN | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(smp2_dur_n))  # ok
display(smp2_dur_n.PCA[:Subj])   # ok
display(smp2_dur_n.PCA[:Item])   # ok

display(VarCorr(smp2_dur_n))
```

```{julia}
#| label: smp3_dur_n

smp3_dur_n = let
  form= @formula(ldur ~ 1 + ACN * Match + 
                       (1 + ACN * Match | Subj) +
                       (1 + ACN | Item));
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(smp3_dur_n))  # not ok
display(smp3_dur_n.PCA[:Subj])   # not ok
display(smp3_dur_n.PCA[:Item])   # not ok

display(VarCorr(smp3_dur_n))
```

```{julia}
#| label: max_dur_n

max_dur_n = let
  form= @formula(ldur ~ 1 + ACN / Match  +
                       (1 + ACN / Match | Subj) +
                       (1 + ACN / Match | Item)); 
  fit(MixedModel, form, gdur[7]; contrasts)
end

display(issingular(max_dur_n))  # not ok

VarCorr(max_dur_n)

```
#### Structure * AntecedentNumber * Match

#### Structure + AntecedentNumber / Match

### Pronoun

#### AntecedentNumber * Match 

#### AntecedentNumber / Match 

### Onset

#### AntecedentNumber * Match 

#### AntecedentNumber / Match 

# GLMMs for accuracy

## AntecedentNumber * Match 

We start with the maximal LMM given the design; it takes about 1 minute to fit.

```{julia}
#| label: max_acc

max_acc = let
  form= @formula(Nerr ~ 1 + ACN * Match + 
                       (1 + ACN * Match | Subj) + 
                       (1 + ACN * Match | Item));
  fit(MixedModel, form, dat_acc, Bernoulli(); contrasts)
end

display(issingular(max_acc))  # ok
display(max_acc.PCA[:Subj])   # ok
display(max_acc.PCA[:Item])   # ok

VarCorr(max_acc)
```

This model looks like it is supported by the data. We are really done.

We  check whether correlation parameters (CPs) are significantly different from zero. 

```{julia}
#| label: zcp_acc

zcp_acc = let
  form= @formula(Nerr ~ 1 + ACN * Match + 
               zerocorr(1 + ACN * Match | Subj) + 
               zerocorr(1 + ACN * Match | Item));
  fit(MixedModel, form, dat_acc, Bernoulli(); contrasts)
end

display(VarCorr(zcp_acc))

coeftable(zcp_acc)
```

No evidence for significant CPs. This looks like a very nice GLMM solution. There is a significant effect of `Match`, but not for `ACN` or the interaction. 

## AntecedentNumber / Match 

 A nested model may be a good _a priori_ alternative LMM, especially if the meaning of  `Match` depends on the `ACN`; in other words if the two factors are not _really_ crossed. 

 ```{julia}
#| label: max_acc_n

max_acc_n = let
  form= @formula(Nerr ~ 1 + ACN / Match + 
                       (1 + ACN / Match | Subj) + 
                       (1 + ACN / Match | Item));
  fit(MixedModel, form, dat_acc, Bernoulli(); contrasts)
end

display(issingular(max_acc_n))
display(max_acc_n.PCA[:Subj])   # ok
display(max_acc_n.PCA[:Item])   # ok

display(VarCorr(max_acc_n))

objective(max_acc)
objective(max_acc_n)
```

Again, the GLMM looks very good. The CPs are larger. 

```{julia}
#| label: zcp_acc_n

zcp_acc_n = let
  form= @formula(Nerr ~ 1 + ACN / Match + 
               zerocorr(1 + ACN / Match | Subj) + 
               zerocorr(1 + ACN / Match | Item));
  fit(MixedModel, form, dat_acc, Bernoulli(); contrasts)
end

display(VarCorr(zcp_acc_n))

coeftable(zcp_acc_n)
```

The `Match` effect is significant in both levels of `ACN`, but very different random-effect structures ...  

```{julia}
objective(zcp_acc)
objective(zcp_acc_n)
```

... and different deviances as well.

# Appendix

```{r}
sessionInfo()
```
