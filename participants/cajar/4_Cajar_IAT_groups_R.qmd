---
title: "Anke Cajar:Borrowing Strength in IAT: Faking Subject"
subtitle: "RePsychLing in SMLP2022"
author: "Reinhold Kliegl"
date: "2022-08-09 (last revised: `r format(Sys.time())`)"
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background

This is a follow-up analysis. We use data from the subjects who faked the second time. We use only three within-subject factors: `Time`, `Block`, and `Switch`. 

# Readme 

## Design

+ Design: 2 (B-Subj/W-Item) x 2 (W) x 2 (W) x 2 (W) factorial mixed design
+ N trials: 38 Subj x 20 Item x 8 W-Item x 2 repetition of items = 12160
+ N errors: 391 (3.2%)
+ N observations: 12160-391=11769

## Variables

+ `Subj`: Participant ID (renamed from `ID`; random factor)
+ `Item`: Word ID (random factor)
+ `Group` (between-Subj/within-Item): 
    + No_Faking: control group, where people took the same normative IAT twice
    + Faking: experimental group, where people were instructed to fake the retest IAT by slowing down response times in the compatible block
+ `Time` (within-Subj/within-Item): 
    + Baseline: first IAT (normative IAT)
    + Retest: second IAT (normative or faked, depending on Group)
+ `Block` (within-Subj/within-Item): 
    + Compatible: IAT combined block with shorter response times
    + Incompatible: IAT combined block with longer response times
+ `Switch` (renamed from `TaskSwitch`; within-Subj/within-Item): 
    + Yes: Switch from target concept to attribute dimension (or the other way around) from one trial to the next 
    + No: No switch from target concept to attribute dimension (or the other way around) from one trial to the next 
+ `rt`: trial response time (DV, renamed from `RT`)

# Load packages

```{r, message=FALSE}
library(arrow)
library(tidyverse)
library(easystats)
library(summarytools)
library(lme4)
library(car)
library(GGally)
library(ellipse)

# respecting color vision deficiency
cbPalette <- c( "#0072B2", "#D55E00", "#009E73", "#CC79A7",
                "#F0E442", "#56B4E9", "#999999", "#E69F00")
```


# Shrinkage (borrowing-strength) plots for non-faking subject

## Fitting a reduced LMM

```{r}
dat <- read_feather("./data/Cajar_IAT.arrow")
dat$speed <- 1000/dat$rt
```

```{r}
iat_fake <- dat |> filter(Group == "Faking")

contrasts(iat_fake$Time)   <- contr.sum(2)
contrasts(iat_fake$Block)  <- contr.sum(2)
contrasts(iat_fake$Switch) <- contr.sum(2)

mm <- model.matrix(~ 1 + Switch*Time*Block, data=iat_fake)
sw <- mm[,2]
tm <- mm[,3]
bl <- mm[,4] 

m_cpx <- lmer(speed ~ 1 + sw*tm*bl + (1 + sw + tm + bl + sw:bl + tm:bl | Subj) ,
              data=iat_fake, REML=FALSE, control=lmerControl(calc.derivs=FALSE))
summary(rePCA(m_cpx))
print(summary(m_cpx), corr=TRUE)
```

+ All interactions are significant (sw:bl; tm:bl)
+ Significant CPs

## No pooling (within-subject OLS estimates)

_Credit_: This and the following sections are heavily inspired by [Tristan Mahr's blog](https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/).

Each subject's data are analyzed with multipe regression without reference to the other subjects, i.e., no pooling of information across subjects. The regression coeffiencents are assembled in a data frame. 


```{r}
coef_ws <- 
  lmList(speed ~ 1 + Switch*Time*Block | Subj, iat_fake) %>%
  coef() %>% 
  select(1:4) |> 
  rename(GM=1, Switch=2, Time=3, Block=4) |> 
  # Item IDs are stored as row-names. Make them an explicit column
  rownames_to_column("Subj") %>% 
  add_column(Pooling = "None") |> 

  as_tibble()

coef_ws
```

## Partial pooling

These are fixed effects plus conditional modes (aka BLUPs) for 19 "faking" subjects.

```{r}
coef_mm <- 
  coef(m_cpx)[["Subj"]] |> 
  select(GM=1, Switch=2, Time=3, Block=4) |> 
  add_column(Subj = pull(coef_ws, "Subj"),
             Pooling = "Partial") |> 
  relocate(Subj) |> 
  as_tibble()

coef_mm
#lattice::splom(~ coef_mm[,2:4])
```

## Complete pooling

Here we ignore that data come from different subjects. We treat the data as independent observations; no clustering is assumed. The fixed effects are centers of gravity in the plots. 

```{r}
gravity <- coef(lm(speed ~ 1 + Switch*Time*Block, iat_fake))[1:4]
names(gravity) <- c("GM", "Switch", "Time", "Block")
gravity <- data.frame(as.list(gravity))
gravity$Subj <- "All"
gravity$Pooling <- "Complete"
gravity <- gravity[,c(5,1:4,6)]
```

## Plots

### SPLOM

Here we compare within-subject estimates (no pooling) and BLUPs (partial pooling). 

```{r}
# Combine no-pooling and partial pooling estimates
coef_ws_mm <- bind_rows(coef_ws, coef_mm)

coef_ws_mm |> 
  mutate(Pooling = fct_rev(Pooling)) |> 
  ggscatmat(columns=2:5, color="Pooling") +
  scale_color_manual("Pooling", values=cbPalette) +
  xlab("") + ylab("") + theme_bw() 
```


+ There is a moderate negative correlation between `GM` and `Switch` effect (i.e., -.33 with no-pooling and -.46 with partial pooling; the corresponding CP was -.39).
+ There is a strong negative correlation between `Time` and `Block` effects, irrespective of no-pooling (-0.8) or partial-pooling (-0.9) of effects. The corresponding CP was -.86.  

### Setup

The following code chunks are taken directly from Tristan Mahr's blog.  

```{r}
# Helper function to make a data-frame of ellipse points that 
# includes the level as a column
make_ellipse <- function(cov_mat, center, level) {
  ellipse(cov_mat, centre = center, level = level) %>%
    as.data.frame() %>%
    add_column(level = level) %>% 
    as_tibble()
}

# Contour lines
levels <- c(.1, .3, .5, .7, .9)

# Strip off some details so that just the useful part is printed
cov_mat <- VarCorr(m_cpx)[["Subj"]]
attr(cov_mat, "stddev") <- NULL
attr(cov_mat, "correlation") <- NULL

# Add complete pooling to ws- and mm-collection of estimates
coef_all <- rbind(gravity, coef_ws_mm)

```

### `GM` over `Switch` costs

We plot individual difference in switch costs over overall mean response speed.

```{r}
center12 <- fixef(m_cpx)[1:2]
cov_mat12 <- cov_mat[1:2, 1:2]

# Create an ellipse dataframe for each of the levels defined 
# above and combine them
df_ellipse12 <- levels %>%
  lapply(
    function(x) make_ellipse(cov_mat12, center12, level = x)
  ) %>% 
  bind_rows() %>% 
  rename(GM = `(Intercept)`, Switch = "sw")

ggplot(coef_all) + 
  aes(x = GM, y = Switch, color = Pooling, shape = Pooling) + 
  # Draw contour lines from the distribution of effects
  geom_path(
    aes(group = level, color = NULL, shape = NULL), 
    data = df_ellipse12, 
    linetype = "dashed", 
    color = "grey40"
  ) + 
  geom_point(
    aes(shape = Pooling),
    data = gravity, 
    size = 5,
    show.legend = FALSE
  ) + 
  geom_point(size = 2) + 
  geom_path(
    aes(group = Subj, color = NULL), 
    arrow = arrow(length = unit(.02, "npc")),
    show.legend = FALSE
  ) + 
  theme(
    legend.position = "bottom", 
    legend.justification = "right"
  ) + 
  ggtitle("Topographic map of regression parameters") + 
  xlab("Grand Mean estimate") + 
  ylab("Switch cost (no-switch trials - switch trials)") + 
  scale_color_brewer(palette = "Dark2") +
  scale_shape_manual(values = c(15:18)) +
  theme_bw() + coord_fixed(ratio=3)
```

The arrows are mostly vertical. This means there is very little shrinakge for the `GM` which is not too surprising, because means have good reliability. The Switch costs, however, are based on difference scores, known for lower reliability. Therefore, for them predictions are a compromise between the subject's data and the population mean. We borrow strength from the population to increase the prediction of the individual. They are pulled towards the center of gravity (i.e.,green square of complete pooling estimates). The pull towards the center of gravity increases the correlation from -.33 for no-pooling estimates to -.47 for partial-pooling estimates. 

We embellished the plot with ellipses to show that even if arrows are not pointing directly at the center of gravity, almost all of them move the conditional mean closer to it when judging their positions with the contour lines.  

#### `Block` effect over `Time` effect

We plot individual difference in slow-down due to incompatibility of required responses over slow-down from baseline to retest. The correlation is negative, that is slowing down reduces the incompatibility effect.

```{r}
center34 <- fixef(m_cpx)[3:4]
cov_mat34 <- cov_mat[3:4, 3:4]

# Create an ellipse dataframe for each of the levels defined 
# above and combine them
df_ellipse34 <- levels %>%
  lapply(
    function(x) make_ellipse(cov_mat34, center34, level = x)
  ) %>% 
  bind_rows() %>% 
  rename(Time = tm, Block = bl)

ggplot(coef_all) + 
  aes(x = Time, y = Block, color = Pooling, shape = Pooling) + 
  # Draw contour lines from the distribution of effects
  geom_path(
    aes(group = level, color = NULL, shape = NULL), 
    data = df_ellipse34, 
    linetype = "dashed", 
    color = "grey40"
  ) + 
  geom_point(
    aes(shape = Pooling),
    data = gravity, 
    size = 5,
    show.legend = FALSE
  ) + 
  geom_point(size = 2) + 
  geom_path(
    aes(group = Subj, color = NULL), 
    arrow = arrow(length = unit(.02, "npc")),
    show.legend = FALSE
  ) + 
  theme(
    legend.position = "bottom", 
    legend.justification = "right"
  ) + 
  ggtitle("Topographic map of regression parameters") + 
  xlab("Time effect (baseline - retest)") + 
  ylab("Block effect (compatible - incompatible)") + 
  scale_color_brewer(palette = "Dark2") +
  scale_shape_manual(values = c(15:18)) +
  theme_bw() + coord_fixed(ratio=1)
```

A positive `Time` effect means increased speed was higher at baseline than retest. This is not implausible for subjects in the "faking" group who were instructed to slow down in speed during retest. Negative values mean that retest speed was higher than baseline speed -- either because subjects did not follow instructions or practice-related improvement was larger than faked slow down. 

A positive `Block` effect means that there is a large difference in speed between compatible and incompatible blocks of trials. Subjects who slowed down much during retests compared to baseline block (i.e., those with very positive `Time` effects) show small `Block` effects. In other words, subjects who acted as instructed and slowed down during retest reduced their incompatibility cost in response speed.

The corresponding plot for the non-fake group does not show this dependency between `GM` and `Switch` costs or `Time` and `Block` effects. Recall that CPs could be forced to zero without loss of goodness of fit, but the four VCs contributed to the goodness of fit, that is there were reliable individual differences associated with them. The corresponding last plot is shown here:

![Shrinkage for Block over Time effects for no-fake group](figures/nofake_bl_tm_shrinkage.jpeg)
Note that the overall `Time`effect is now negative (i.e., speed was higher during retest than baseline). The correlation is weaker, but still negative (albeit not significant!).  Nevertheless, given the small sample size, we could conclude that the instruction-induced slowing effect is also visible when looking at interindividual differences in response speed. 

# Appendix

```{r}
sessionInfo()
```
