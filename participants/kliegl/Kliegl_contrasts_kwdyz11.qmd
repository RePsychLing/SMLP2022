---
title: "Contrast Coding of Visual Attention Effects"
author: "Reinhold Kliegl"
date: "2022-09-09 (last revised: `r format(Sys.time())`)"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
    fig-format: svg
editor_options:
  chunk_output_type: console
---

# A word of caution

For a (quasi-)experimental set of data, there is (or should be) a clear a priori theoretical committment to specific hypotheses about differences between factor levels and how these differences enter in interactions with other factors. This specification should be used in the first LMM and reported, irrespective of the outcome. If alternative theories lead to alternative a priori contrast specifications, both analyses are justified. If the observed means render the specification completely irrelevant, the planned comparisons could still be repor in a Supplement).

In this script, we are working through a large number of different contrasts for the same data. The purpose is to introduce both the preprogrammed (“canned”) and the general options to specify hypotheses about such related to main effects and interactions. Obviously, we do not endorse generating a plot of the means and specifying the contrasts accordingly. This is known as the Texas sharpshooter fallacy. Here is a link to an illustration and brief historical account by Wagenmakers (2018)

If results do not turn out as expected, there is nothing wrong with specifying a set of post-hoc contrasts to gain a better understanding of what the data are trying to tell us. In a report the a priori and post-hoc nature of contrast specifications must be made clear. Some kind of alpha-level adjustment (e.g., Bonferroni) may be called for, too. And, of course, there are grey zones.

There is quite a bit of literature on contrasts. Two “local” references are:

Brehm, L., & Alday, P. M., (2022). Contrast coding choices in a decade of mixed models. Journal of Memory and Language, 125, 104334.

+ [URL](https://pure.mpg.de/rest/items/item_3384534_1/component/file_3384535/content)
+ [OSF](https://osf.io/jkpxt/)

Schad, D. J., Vasishth, S., Hohenstein, S., & Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: A tutorial. Journal of Memory and Language, 110, 104038.

+ [URL](https://www.sciencedirect.com/science/article/pii/S0749596X19300695)
+ [OSF](https://osf.io/7ukf6/)

For further readings see “Further Readings” in Schad et al. (2020).

# Example data 

We take the `KWDYZ` dataset from [Kliegl et al. (2011, _Front. Psychol._)](https://doi.org/10.3389/fpsyg.2010.00238).
This is an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs).
Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point.
Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles.
The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each.

We specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention.
They map onto sequential differences between appropriately ordered factor levels.
Interestingly, a different theoretical perspective, derived from feature overlap, leads to a different set of contrasts.
Can the results refute one of the theoretical perspectives?

We also have a dataset from a replication and extension of this study (Kliegl, Kuschela, & Laubrock, 2015).
Both data sets are available in [R-package RePsychLing](https://github.com/dmbates/RePsychLing/tree/master/data/)

# Setup

```{julia}
#| code-fold: true
#| 
using Arrow
using Chain
using DataFrames
using DataFrameMacros
using MixedModels
using ProgressMeter
using StatsBase
using StatsModels
using StatsModels: ContrastsCoding

ProgressMeter.ijulia_behavior(:clear);
```

# Preprocessing {#sec-preprocessing}

```{julia}
dat1 = @chain "./data/kwdyz11.arrow" begin
  Arrow.Table
  DataFrame
  select!(:subj => :Subj, :tar => :CTR, :rt)
end
cellmeans = combine(
  groupby(dat1, [:CTR]),
  :rt => mean,
  :rt => std,
  :rt => length,
  :rt => (x -> std(x) / sqrt(length(x))) => :rt_semean,
)
```

# Constant across script

```{julia}
display(StatsModels.levels(dat1.CTR))
form = @formula rt ~ 1 + CTR + (1 + CTR | Subj)
```

# Contrast options

## SeqDiff Coding

This contrast corresponds to `MASS::contr.sdif()` in R.

```{julia}


m1 = let
  contrasts = Dict(
    :CTR => SeqDiffCoding(; levels=StatsModels.levels(dat1.CTR)), 
    :Subj => Grouping()
  )
  fit(MixedModel, form, dat1; contrasts)
end
```

## Hypothesis Coding

This contrast corresponds to `MASS::contr.sdif()` in R.
A general solution (not inverse of last contrast)

```{julia}
m1b = let
  contrasts = Dict(
    :CTR => HypothesisCoding(
      [
       -1  1 0  0
        0 -1 1  0
        0  0 1 -1
      ];
      levels=StatsModels.levels(dat1.CTR),
      labels=["spt", "obj", "grv"],
    ),
  )
  fit(MixedModel, form, dat1; contrasts)
end
```

Controlling the ordering of levels for contrasts:

 1. kwarg `levels` to order the levels; the first is set as the baseline.
 2. kwarg `base=` to fix the baseline level.

## Dummy Coding

This contrast corresponds to `contr.treatment()` in R

```{julia}
m2 = let
  contrasts = Dict(:CTR => DummyCoding(; base="val"))
  fit(MixedModel, form, dat1; contrasts)
end
```

This contrast has the disadvantage that the intercept returns the mean of the level specified as `base`, default is the first level, not the GM.

## Ychycaeit Coding

The contrasts returned by `DummyCoding` may be what you want.
Can't we have them, but also the GM rather than the mean of the base level?
Yes, we can!
I call this "You can have your cake and it eat, too"-Coding (YchycaeitCoding).

```{julia}
m2b = let
  contrasts = Dict(
    :CTR => HypothesisCoding(
      [
        -1 1 0 0
        -1 0 1 0
        -1 0 0 1
      ];
      levels=StatsModels.levels(dat1.CTR),
    )
  )
  fit(MixedModel, form, dat1; contrasts)
end
```

Just relevel the factor or move the column with -1s for a different base.

## Effects Coding 

This contrast corresponds almost to `contr.sum()` in R

```{julia}
m3 = let
  contrasts = Dict(:CTR => EffectsCoding(; 
                    levels=StatsModels.levels(dat1.CTR), 
                    base="dod"))
  fit(MixedModel, form, dat1; contrasts)
end
```

## Helmert Coding

Helmert contrasts are othogonal.

Helmert coding codes each level as the difference from the average of the lower levels. With the default order of `CTR` levels we get the following test statistics.

```{julia}
m4 = let
  contrasts = Dict(:CTR => HelmertCoding(;
                    levels=StatsModels.levels(dat1.CTR)))
  fit(MixedModel, form, dat1; contrasts)
end
```

```sh
+ HeC1: (2 - 1)/2           # (391 - 358)/2
+ HeC2: (3 - (2+1)/2)/3     # (405 - (391 + 358)/2)/3
+ HeC3: (4 - (3+2+1)/3)/4   # (402 - (405 + 391 + 358)/3)/4
```
## Reverse Helmert Coding

```{julia}
display(reverse(StatsModels.levels(dat1.CTR)))
m4b = let
  levels = reverse(StatsModels.levels(dat1.CTR))
  contrasts = Dict(:CTR => HelmertCoding(; levels))
  fit(MixedModel, form, dat1; contrasts)
end
```

```sh
+ HeC1:(3 - 4)/2            # (405 - 402)/2
+ HeC2:(2 - (3+4)/2)/3      # (391 - (405 + 402)/2)/3
+ HeC3:(1 - (2+3+4)/3/4     # (356  -(391 + 405 + 402)/3)/4 
```

## Anova Coding - Anova contrasts are orthogonal.

### A(2) x B(2)

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2).
The following contrast specifiction returns estimates for the main effect of A, the main effect of B, and the interaction of A and B.
In a figure With A on the x-axis and the levels of B shown as two lines, the interaction tests the null hypothesis that the two lines are parallel.
A positive coefficient implies overadditivity (diverging lines toward the right) and a negative coefficient underadditivity (converging lines).

```{julia}
m5 = let
  contrasts = Dict(
    :CTR => HypothesisCoding(
      [
        -1 -1 +1 +1          # A
        -1 +1 -1 +1          # B
        +1 -1 -1 +1          # A x B
      ];
      levels=StatsModels.levels(dat1.CTR),
      labels=["A", "B", "AxB"],
    ),
  )
  fit(MixedModel, form, dat1; contrasts)
end
```

It is also helpful to see the corresponding layout of the four means for the interaction of A and B (i.e., the third contrast)

```
        B1     B2
   A1   +1     -1
   A2   -1     +1
```

Thus, interaction tests whether the difference between main diagonal and minor diagonal is different from zero.

### A(2) x B(2) x C(2)

Going beyond the four level factor; it is also helpful to see the corresponding layout of the eight means for the interaction of A and B and C.

```
          C1              C2
      B1     B2        B1     B2
 A1   +1     -1   A1   -1     +1
 A2   -1     +1   A2   +1     -1
```

### A(2) x B(2) x C(3)

TO BE DONE

## Nested Coding

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2).
The following contrast specifiction returns an estimate for the main effect of A and the effects of B nested in the two levels of A.
In a figure With A on the x-axis and the levels of B shown as two lines, the second contrast tests whether A1-B1 is different from A1-B2 and the third contrast tests whether A2-B1 is different from A2-B2.

```{julia}
m8 = let
  contrasts = Dict(
    :CTR => HypothesisCoding(
      [
      -1 -1 +1 +1
      -1 +1  0  0
       0  0 +1 -1
      ];
      levels=StatsModels.levels(dat1.CTR),
      labels=["do_so", "spt", "grv"],
    ),
  )
  fit(MixedModel, form, dat1; contrasts)
end
```

The three contrasts for one main effect and two nested contrasts are orthogonal.
There is no test of the interaction (parallelism).

## Other orthogonal contrasts

For factors with more than four levels there are many options for specifying orthogonal contrasts as long as one proceeds in a top-down strictly hiearchical fashion.

Suppose you have a factor with seven levels and let's ignore shifting colummns.
In this case, you have six options for the first contrast, that is 6 vs. 1, 5 vs.2 , 4 vs. 3, 3 vs. 4, 2 vs. 5, and 1 vs. 6 levels.
Then, you specify orthogonal contrasts for partitions with more than 2 elements and so on.
That is, you don't specify a contrast that crosses an earlier partition line.

In the following example, after an initial 4 vs 3 partitioning of levels, we specify `AnovaCoding` for the left and `HelmertCoding` for the right partition.

```{julia}
contrasts = Dict(
  :CTR => HypothesisCoding(
    [
      -1/4 -1/4 -1/4 -1/4 +1/3 +1/3 +1/3
      -1/2 -1/2 +1/2 +1/2    0    0    0
      -1/2 +1/2 -1/2 +1/2    0    0    0
      +1/2 -1/2 -1/2 +1/2    0    0    0
         0    0    0    0   -1   +1    0
         0    0    0    0 -1/2 -1/2    1
    ];
    levels=["A1", "A2", "A3", "A4", "A5", "A6", "A7"],
    labels=["c567.1234", "B", "C", "BxC", "c6.5", "c6.56"],
  ),
);
```

There are two rules that hold for all orthogonal contrasts:

 1. The weights within rows sum to zero.
 2. For all pairs of rows, the sum of the products of weights in the same columns sums to zero.

# Appendix: Summary (Dave Kleinschmidt)

[StatsModels](https://juliastats.org/StatsModels.jl/latest/contrasts/)

StatsModels.jl provides a few commonly used contrast coding schemes, some less-commonly used schemes, and structs that allow you to manually specify your own, custom schemes.

## Standard contrasts

The most commonly used contrasts are `DummyCoding` and `EffectsCoding` (which are similar to `contr.treatment()` and `contr.sum()` in R, respectively).

## "Exotic" contrasts (rk: well ...)

We also provide `HelmertCoding` and `SeqDiffCoding` (corresponding to base R's `contr.helmert()` and `MASS::contr.sdif()`).

## Manual contrasts

**ContrastsCoding()**

There are two ways to manually specify contrasts.
First, you can specify them **directly** via `ContrastsCoding`.
If you do, it's good practice to specify the levels corresponding to the rows of the matrix, although they can be omitted in which case they'll be inferred from the data.

**HypothesisCoding()**

A better way to specify manual contrasts is via `HypothesisCoding`, where each row of the matrix corresponds to the weights given to the cell means of the levels corresponding to each column (see @Schad2020 for more information).
