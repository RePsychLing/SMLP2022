---
title: "Oliver Lindemann: Cardiac Synchrony and its Role in Language Development"
subtitle: "RePsychLing in SMLP2022"
author: "Reinhold Kliegl"
date: "2022-08-31"
format: 
  html:
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options: 
  chunk_output_type: console
jupyter: julia-1.8
---

# Background 



#

# Setup

```{julia}
#| label: packages

using AlgebraOfGraphics
using Arrow
using CairoMakie       # graphics back-end
using CategoricalArrays
using Chain
using DataFrames
using DataFrameMacros  # simplified dplyr-like data wrangling 
using KernelDensity    # density estimation
using MixedModels
using MixedModelsMakie # diagnostic plots
if contains(first(Sys.cpu_info()).model, "Intel")
  using MKL             # faster LAPACK on Intel processors
end
using ProgressMeter
using Random           # random number generators
using RCall            # call R from Julia
using StatsBase
using StatsModels


ProgressMeter.ijulia_behavior(:clear);
CairoMakie.activate!(; type="svg");
```


```{julia}
dat = DataFrame(Arrow.Table("./data/Vanoncini_lang_ECG.arrow"));

# transfromations using DataFrameMacros
@transform!(dat, :Fam = @bycol categorical(:Fam));
@transform!(dat, :llt = log(:lt));
@transform!(dat, "{}_c" =  @bycol ({r"^pc"} .- mean({r"^pc"})));

describe(dat)

# last line is shortcut for:
#@transform!(dat, :pc1_c = @bycol (:pc1 .- mean(:pc1)));
#@transform!(dat, :pc2_c = @bycol (:pc2 .- mean(:pc2)));
#@transform!(dat, :pc3_c = @bycol (:pc3 .- mean(:pc3)));

# Alternative: transformations using DataFrames
#transform!(dat, :Fam => categorical => :Fam,
#                :lt  => (x -> log.(x)) => :llt);

```

# Further preprocessing with R

```{julia}
#| label: fig-speed 
#| fig-cap: Profile likelihood function for power-transformation coefficient λ (Box & Cox, 1964). Also shown is the 95% confidence interval.  A log-transformation is indicated for λ = 0. 

RCall.ijulia_setdevice(MIME("image/svg+xml"); width=10, height=10.0)
@rput dat;
#R"summary(dat)"

R"""
suppressWarnings(suppressMessages(library(tidyverse)))

MASS::boxcox(lt ~ 1 + Fam + Subj, data=dat)
""";
```

# Linear mixed models 

## Contrasts

```{julia}
contrasts = merge(
      Dict(:Fam => EffectsCoding(base= "familiar"; levels=["familiar", "novel"])),
      Dict(:Subj => Grouping())
   );
```

## LMM analysis

```{julia}
#| lst-label: m_pc0
m_pc0 = let 
    form = @formula(llt ~  1 + Fam + (1 | Subj));
    fit(MixedModel, form, dat; contrasts);
  end
```

```{julia}
#| lst-label: m_pc1
m_pc1 = let 
    form = @formula(llt ~  1 + Fam*pc1_c + (1 | Subj));
    fit(MixedModel, form, dat; contrasts);
  end
```

```{julia}
#| lst-label: m_pc2
m_pc2 = let 
    form = @formula(llt ~  1 + Fam*(pc1_c + pc2_c) + (1 | Subj));
    fit(MixedModel, form, dat; contrasts);
  end
```

```{julia}
#| lst-label: m_pc3
m_pc3 = let 
    form = @formula(llt ~  1 + Fam*(pc1_c + pc2_c + pc3_c)  + (1 | Subj));
    fit(MixedModel, form, dat; contrasts);
  end
```

# Compare models

```{julia}
display(lrtest(m_pc0, m_pc1, m_pc2, m_pc3))

 lrtest(m_pc0, m_pc3)
```

```{julia}
MixedModels.likelihoodratiotest(m_pc0, m_pc1, m_pc2, m_pc3)
```

```{julia}
let mods = [m_pc0, m_pc1, m_pc2, m_pc3];
 DataFrame(;
    model=[:m_pc0, :m_pc1, :m_pc2, :m_pc3],
    pars=dof.(mods),
    geomdof=round.(Int, (sum ∘ leverage).(mods)),
    AIC=round.(Int, aic.(mods)),
    AICc=round.(Int, aicc.(mods)),
    BIC=round.(Int, bic.(mods)),
  )
end
```

Not much evidence for the relevance of the principal-component predictors.

# Appendix
```{julia}
versioninfo()
```

