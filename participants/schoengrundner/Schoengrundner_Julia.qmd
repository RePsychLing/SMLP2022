---
title: "Patrick Schöngrundner: GLMM Simulations"
subtitle: "Using MixedModels.jl"
author: "Reinhold Kliegl"
date: "2022-09-09"
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options: 
  chunk_output_type: console
jupyter: julia-1.8
---

# Background 

For a descripton see Example1.HTML.

Data are from simulating the following design:

+ Design: 2 (`Sex`: B-Subj/W-Item) x 2 (`Item`: W-Subj/B-Item) factorial mixed design ...
+ ... with 18 `Subj` (9 male, 9 female) x 18 `Item` (9 pos images, 9 negative images)= 324 responses
+ `Cat`: positive (A) vs. negative (B) categroy of image/item
+ `resp`: dependent variable: Are you scared? Yes/No; (Bernoulli 0/1 variable)

# Setup

## Environment

```{julia}
#| label: environment
#| echo: false
#| output: false
using Pkg; Pkg.activate(".")
```

## Packages

```{julia}
#| label: packages

using AlgebraOfGraphics
using Arrow
using CairoMakie       # graphics back-end
using CategoricalArrays
using Chain
using CSV
using DataFrames
using DataFrameMacros  # simplified dplyr-like data wrangling 
using KernelDensity    # density estimation
using MixedModels
using MixedModelsMakie # diagnostic plots
using ProgressMeter
using Random           # random number generators
using RCall            # call R from Julia
using StatsBase
using StatsModels

using AlgebraOfGraphics: density
using AlgebraOfGraphics: boxplot
using MixedModelsMakie: qqnorm
using MixedModelsMakie: ridgeplot
using MixedModelsMakie: scatter

ProgressMeter.ijulia_behavior(:clear);
CairoMakie.activate!(; type="svg");
## Read the original data file
```

## Read simulated data sets

```{julia}
dat1 = CSV.read("./data/DataEx1.csv", DataFrame; pool=true)
dat1 = rename(dat1, :subj_ID => :Subj, :subj_sex => :Sex, :item_ID => :Item, :item_cat => :Cat)
dat1=@transform dat1 :Sex = @bycol categorical(:Sex)
dat1=@transform dat1 :Cat = @bycol categorical(:Cat)
describe(dat1)
```

```{julia}
dat2 = CSV.read("./data/DataEx2.csv", DataFrame; pool=true)
describe(dat2)
dat2 = rename(dat2, :subj_ID => :Subj, :subj_sex => :Sex, :item_ID => :Item, :item_cat => :Cat)
dat2 = @transform dat2 :Sex = @bycol categorical(:Sex)
dat2 = @transform dat2 :Cat = @bycol categorical(:Cat)
```

## Converting `Subj` and `Item` columns to factors

Paraphrasing Douglas Bates: Convert the integer `Subj` and `Item` values, which are between 1 and 18, to character strings of the form `S01` to `S18` and `I01` to `I18`, then convert these to a categorical array (similar to a factor in R). Note that we left-pad the numbers with zeros to a given length (2, in this case) so that sorting the strings lexicographically corresponds to sorting by numerical value.

```{julia}
dat1.Subj = let
  strv = string.('S', lpad.(dat1.Subj, 2, '0'))
  categorical(strv; levels=sort(unique(strv)))
end;

dat1.Item = let
  strv = string.('I', lpad.(dat1.Item, 2, '0'))
  categorical(strv; levels=sort(unique(strv)))
end

dat2.Subj = let
  strv = string.('S', lpad.(dat2.Subj, 2, '0'))
  categorical(strv; levels=sort(unique(strv)))
end;

dat2.Item = let
  strv = string.('I', lpad.(dat2.Item, 2, '0'))
  categorical(strv; levels=sort(unique(strv)))
end;
```

## Contrasts

```{julia}
contrasts =  Dict(:Sex   => EffectsCoding(),
                  :Cat   => EffectsCoding(),
                  :Subj  => Grouping(),
                  :Item  => Grouping());
```

# Basic GLMM fit

## ... using factors

```{julia}
frm1a = @formula(resp ~ 1 + Sex*Cat + (1|Subj) + (1|Item));
fit1a = fit(MixedModel, frm1a, dat1, Bernoulli(); contrasts)
```

## ... using PS's indicator variables

```{julia}
frm1b = @formula(resp ~ 1 + sex1*cat1 + (1|Subj) + (1|Item));
fit1b= fit(MixedModel, frm1b, dat1, Bernoulli())
```

## ... extracting indicator variables from the model matrix

The indicator variables in the dataframe are also available from the factor-based model matrix.

```{julia}
mm1 = fit1a.X;
dat1[!, :sex] = mm1[:, 2]
dat1[!, :cat] = mm1[:, 3]

frm1c = @formula(resp ~ 1 + sex*cat + (1|Subj) + (1|Item));
fit1c= fit(MixedModel, frm1c, dat1, Bernoulli())
```

## Compare models

```{julia}
display(MixedModels.likelihoodratiotest(fit1a, fit1b, fit1c))

let mods = [fit1a, fit1b, fit1c];
 DataFrame(;
    model=[:fit1a, :fit1b, :fit1c],
    pars=dof.(mods),
    AIC=round.(Int, aic.(mods)),
    AICc=round.(Int, aicc.(mods)),
    BIC=round.(Int, bic.(mods)),
  )
end
```

# Boosted-parameter GLMM fit

## ... using factors

```{julia}
frm2a = @formula(resp ~ 1 + Sex*Cat + (1|Subj) + (1|Item));
fit2a = fit(MixedModel, frm2a, dat2, Bernoulli(); contrasts)
```

## ... using PS's indicator variables

```{julia}
frm2b = @formula(resp ~ 1 + sex1*cat1 + (1|Subj) + (1|Item));
fit2b= fit(MixedModel, frm2b, dat2, Bernoulli())
```

## ... extracting indicator variables from the model matrix

The indicator variables in the dataframe are also available from the factor-based model matrix.

```{julia}
mm2 = fit2a.X;
dat2[!, :sex] = mm2[:, 2]
dat2[!, :cat] = mm2[:, 3]

frm2c = @formula(resp ~ 1 + sex*cat + (1|Subj) + (1|Item));
fit2c= fit(MixedModel, frm2c, dat2, Bernoulli())
```

## Compare models

```{julia}
display(MixedModels.likelihoodratiotest(fit2a, fit2b, fit2c))

let mods = [fit2a, fit2b, fit2c];
 DataFrame(;
    model=[:fit2a, :fit2b, :fit2c],
    pars=dof.(mods),
    AIC=round.(Int, aic.(mods)),
    AICc=round.(Int, aicc.(mods)),
    BIC=round.(Int, bic.(mods)),
  )
end
```

# Parametric bootstrap

Using LMM `fit1a`  we:

  - generate a bootstrap sample
  - compute shortest covergage intervals for the LMM parameters
  - plot densities of bootstrapped parameter estimates for fixed effects and variance components

## Generate a bootstrap sample

We generate 2500 samples for the 6 model parameters (4 fixed effects and 2 VCs).

```{julia}
Random.seed!(42)
samp = parametricbootstrap(2500, fit1a);
```

```{julia}
dat3 = DataFrame(samp.allpars)
first(dat3, 10)
```

Sometimes the bootstrap does not work, ...

```{julia}
@subset(dat3, :value != NaN)
display(describe(dat3))
nrow(dat3) # 2500 estimates for each of 6 model parameters
```

... but in this case we did not lose any estimates. 

## Shortest coverage interval

```{julia}
sci = DataFrame(shortestcovint(samp))
```

We can also visualize the shortest coverage intervals for fixed effects with the `ridgeplot()` command:

```{julia}
#| code-fold: true
#| label: fig-bsridgem1
#| fig-cap: Ridge plot of fixed-effects bootstrap samples from model m_KM
ridgeplot(samp; show_intercept=false)
```

## Comparative density plots of bootstrapped parameter estimates

### Fixed effects (w/o GM)

```{julia}
#| code-fold: true
#| label: fig-betadensity_fe
#| fig-cap: '  Kernel density estimate from bootstrap samples of the fixed effects for model  m1L'
rn = renamer([
  "(Intercept)" => "GM",
  "Sex: M" => "Sex effect",
  "Cat: B" => "Image category effect",
  "Sex: M & Cat: B" => "Sex x Cat interaction effect"
])
draw(
  data(@subset(dat3, :type == "β" && :names ≠ "(Intercept)")) *
  mapping(
    :value => "Experimental effect size [ms]";
    color=:names => rn => "Experimental effects",
  ) *
  density();
  figure=(; resolution=(800, 350)),
)
```

The densitiies correspond nicely with the shortest coverage intervals.

### VCs  for `Subj` and `Item`

```{julia}
#| code-fold: true
#| label: fig-sigmasdensitym_Subj
#| fig-cap: '  Kernel density estimate from bootstrap samples of `Subj`-related VC for GM'
draw(
  data(@subset(dat3, :type == "σ" &&  :group == "Subj")) *
  mapping(
    :value => "Standard deviation [ms]"
  ) *
  density();
  figure=(; resolution=(800, 350)),
)
```

```{julia}
#| code-fold: true
#| label: fig-sigmasdensitym_Item
#| fig-cap: '  Kernel density estimate from bootstrap samples of `Item`-related VC for GM'
draw(
  data(@subset(dat3, :type == "σ" &&  :group == "Item")) *
  mapping(
    :value => "Standard deviation [ms]"
  ) *
  density();
  figure=(; resolution=(800, 350)),
)
```

# Appendix

```{julia}
versioninfo()
```


